// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang -std=c++11 -S -O2 -mavx2 -o - %s | FileCheck -check-prefix=CHECK-AVX2 %s
#include "dimsum.h"
using namespace dimsum;

extern "C" {

// CHECK-AVX2-LABEL: cmp_eq_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_eq_0(NativeSimd<int8> a, NativeSimd<int8> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_eq_1(NativeSimd<int16> a, NativeSimd<int16> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_eq_2(NativeSimd<int32> a, NativeSimd<int32> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqq %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_eq_3(NativeSimd<int64> a, NativeSimd<int64> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_eq_4(NativeSimd<uint8> a, NativeSimd<uint8> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_eq_5(NativeSimd<uint16> a, NativeSimd<uint16> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_eq_6(NativeSimd<uint32> a, NativeSimd<uint32> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqq %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_eq_7(NativeSimd<uint64> a, NativeSimd<uint64> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpeqps %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_eq_8(NativeSimd<float> a, NativeSimd<float> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_eq_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpeqpd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_eq_9(NativeSimd<double> a, NativeSimd<double> b) {
  return cmp_eq(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_ne_0(NativeSimd<int8> a, NativeSimd<int8> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_ne_1(NativeSimd<int16> a, NativeSimd<int16> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_ne_2(NativeSimd<int32> a, NativeSimd<int32> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqq %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_ne_3(NativeSimd<int64> a, NativeSimd<int64> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_ne_4(NativeSimd<uint8> a, NativeSimd<uint8> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_ne_5(NativeSimd<uint16> a, NativeSimd<uint16> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_ne_6(NativeSimd<uint32> a, NativeSimd<uint32> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpeqq %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_ne_7(NativeSimd<uint64> a, NativeSimd<uint64> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpneqps %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_ne_8(NativeSimd<float> a, NativeSimd<float> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_ne_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpneqpd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_ne_9(NativeSimd<double> a, NativeSimd<double> b) {
  return cmp_ne(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtb %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_lt_0(NativeSimd<int8> a, NativeSimd<int8> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtw %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_lt_1(NativeSimd<int16> a, NativeSimd<int16> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtd %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_lt_2(NativeSimd<int32> a, NativeSimd<int32> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtq %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_lt_3(NativeSimd<int64> a, NativeSimd<int64> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovdqa {{.*#+}} ymm2 = [128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpcmpgtb %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_lt_4(NativeSimd<uint8> a, NativeSimd<uint8> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovdqa {{.*#+}} ymm2 = [32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpcmpgtw %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_lt_5(NativeSimd<uint16> a, NativeSimd<uint16> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpbroadcastd {{.*#+}} ymm2 = [2147483648,2147483648,2147483648,2147483648,2147483648,2147483648,2147483648,2147483648]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpcmpgtd %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_lt_6(NativeSimd<uint32> a, NativeSimd<uint32> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpbroadcastq {{.*#+}} ymm2 = [9223372036854775808,9223372036854775808,9223372036854775808,9223372036854775808]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpcmpgtq %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_lt_7(NativeSimd<uint64> a, NativeSimd<uint64> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpltps %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_lt_8(NativeSimd<float> a, NativeSimd<float> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_lt_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpltpd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_lt_9(NativeSimd<double> a, NativeSimd<double> b) {
  return cmp_lt(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_le_0(NativeSimd<int8> a, NativeSimd<int8> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_le_1(NativeSimd<int16> a, NativeSimd<int16> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_le_2(NativeSimd<int32> a, NativeSimd<int32> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtq %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_le_3(NativeSimd<int64> a, NativeSimd<int64> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpminub %ymm1, %ymm0, %ymm1
// CHECK-AVX2-NEXT:    vpcmpeqb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_le_4(NativeSimd<uint8> a, NativeSimd<uint8> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpminuw %ymm1, %ymm0, %ymm1
// CHECK-AVX2-NEXT:    vpcmpeqw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_le_5(NativeSimd<uint16> a, NativeSimd<uint16> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpminud %ymm1, %ymm0, %ymm1
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_le_6(NativeSimd<uint32> a, NativeSimd<uint32> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpbroadcastq {{.*#+}} ymm2 = [9223372036854775808,9223372036854775808,9223372036854775808,9223372036854775808]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpgtq %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_le_7(NativeSimd<uint64> a, NativeSimd<uint64> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpleps %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_le_8(NativeSimd<float> a, NativeSimd<float> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_le_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmplepd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_le_9(NativeSimd<double> a, NativeSimd<double> b) {
  return cmp_le(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_gt_0(NativeSimd<int8> a, NativeSimd<int8> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_gt_1(NativeSimd<int16> a, NativeSimd<int16> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_gt_2(NativeSimd<int32> a, NativeSimd<int32> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtq %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_gt_3(NativeSimd<int64> a, NativeSimd<int64> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovdqa {{.*#+}} ymm2 = [128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpgtb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_gt_4(NativeSimd<uint8> a, NativeSimd<uint8> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovdqa {{.*#+}} ymm2 = [32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768,32768]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpgtw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_gt_5(NativeSimd<uint16> a, NativeSimd<uint16> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpbroadcastd {{.*#+}} ymm2 = [2147483648,2147483648,2147483648,2147483648,2147483648,2147483648,2147483648,2147483648]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpgtd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_gt_6(NativeSimd<uint32> a, NativeSimd<uint32> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpbroadcastq {{.*#+}} ymm2 = [9223372036854775808,9223372036854775808,9223372036854775808,9223372036854775808]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpcmpgtq %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_gt_7(NativeSimd<uint64> a, NativeSimd<uint64> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpltps %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_gt_8(NativeSimd<float> a, NativeSimd<float> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_gt_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpltpd %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_gt_9(NativeSimd<double> a, NativeSimd<double> b) {
  return cmp_gt(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtb %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_ge_0(NativeSimd<int8> a, NativeSimd<int8> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtw %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_ge_1(NativeSimd<int16> a, NativeSimd<int16> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtd %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_ge_2(NativeSimd<int32> a, NativeSimd<int32> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpcmpgtq %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_ge_3(NativeSimd<int64> a, NativeSimd<int64> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpmaxub %ymm1, %ymm0, %ymm1
// CHECK-AVX2-NEXT:    vpcmpeqb %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> cmp_ge_4(NativeSimd<uint8> a, NativeSimd<uint8> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpmaxuw %ymm1, %ymm0, %ymm1
// CHECK-AVX2-NEXT:    vpcmpeqw %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> cmp_ge_5(NativeSimd<uint16> a, NativeSimd<uint16> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpmaxud %ymm1, %ymm0, %ymm1
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_ge_6(NativeSimd<uint32> a, NativeSimd<uint32> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vpbroadcastq {{.*#+}} ymm2 = [9223372036854775808,9223372036854775808,9223372036854775808,9223372036854775808]
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    vpxor %ymm2, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpcmpgtq %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
// CHECK-AVX2-NEXT:    vpxor %ymm1, %ymm0, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_ge_7(NativeSimd<uint64> a, NativeSimd<uint64> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmpleps %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> cmp_ge_8(NativeSimd<float> a, NativeSimd<float> b) {
  return cmp_ge(a, b);
}

// CHECK-AVX2-LABEL: cmp_ge_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vcmplepd %ymm0, %ymm1, %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> cmp_ge_9(NativeSimd<double> a, NativeSimd<double> b) {
  return cmp_ge(a, b);
}

}
