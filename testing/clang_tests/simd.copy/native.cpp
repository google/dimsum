// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang -std=c++11 -S -O2 -mavx2 -o - %s | FileCheck -check-prefix=CHECK-AVX2 %s
#include "dimsum.h"
using namespace dimsum;

extern "C" {

// CHECK-AVX2-LABEL: copy_from_element_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<int8> copy_from_element_0(int8* a) {
  NativeSimd<int8> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<int16> copy_from_element_1(int16* a) {
  NativeSimd<int16> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<int32> copy_from_element_2(int32* a) {
  NativeSimd<int32> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<int64> copy_from_element_3(int64* a) {
  NativeSimd<int64> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> copy_from_element_4(uint8* a) {
  NativeSimd<uint8> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> copy_from_element_5(uint16* a) {
  NativeSimd<uint16> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> copy_from_element_6(uint32* a) {
  NativeSimd<uint32> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> copy_from_element_7(uint64* a) {
  NativeSimd<uint64> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<float> copy_from_element_8(float* a) {
  NativeSimd<float> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_element_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<double> copy_from_element_9(double* a) {
  NativeSimd<double> r;
  r.copy_from(a, flags::element_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<int8> copy_from_vector_0(int8* a) {
  NativeSimd<int8> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<int16> copy_from_vector_1(int16* a) {
  NativeSimd<int16> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<int32> copy_from_vector_2(int32* a) {
  NativeSimd<int32> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<int64> copy_from_vector_3(int64* a) {
  NativeSimd<int64> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint8> copy_from_vector_4(uint8* a) {
  NativeSimd<uint8> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint16> copy_from_vector_5(uint16* a) {
  NativeSimd<uint16> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint32> copy_from_vector_6(uint32* a) {
  NativeSimd<uint32> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<uint64> copy_from_vector_7(uint64* a) {
  NativeSimd<uint64> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<float> copy_from_vector_8(float* a) {
  NativeSimd<float> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_from_vector_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps (%rdi), %ymm0
// CHECK-AVX2-NEXT:    retq
NativeSimd<double> copy_from_vector_9(double* a) {
  NativeSimd<double> r;
  r.copy_from(a, flags::vector_aligned);
  return r;
}

// CHECK-AVX2-LABEL: copy_to_element_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_0(NativeSimd<int8> a, int8* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_1(NativeSimd<int16> a, int16* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_2(NativeSimd<int32> a, int32* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_3(NativeSimd<int64> a, int64* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_4(NativeSimd<uint8> a, uint8* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_5(NativeSimd<uint16> a, uint16* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_6(NativeSimd<uint32> a, uint32* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_7(NativeSimd<uint64> a, uint64* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_8(NativeSimd<float> a, float* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_element_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovups %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_element_9(NativeSimd<double> a, double* b) {
  a.copy_to(b, flags::element_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_0:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_0(NativeSimd<int8> a, int8* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_1:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_1(NativeSimd<int16> a, int16* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_2:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_2(NativeSimd<int32> a, int32* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_3:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_3(NativeSimd<int64> a, int64* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_4:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_4(NativeSimd<uint8> a, uint8* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_5:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_5(NativeSimd<uint16> a, uint16* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_6:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_6(NativeSimd<uint32> a, uint32* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_7:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_7(NativeSimd<uint64> a, uint64* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_8:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_8(NativeSimd<float> a, float* b) {
  a.copy_to(b, flags::vector_aligned);
}

// CHECK-AVX2-LABEL: copy_to_vector_9:
// CHECK-AVX2:       # %bb.0: # %entry
// CHECK-AVX2-NEXT:    vmovaps %ymm0, (%rdi)
// CHECK-AVX2-NEXT:    vzeroupper
// CHECK-AVX2-NEXT:    retq
void copy_to_vector_9(NativeSimd<double> a, double* b) {
  a.copy_to(b, flags::vector_aligned);
}

}
